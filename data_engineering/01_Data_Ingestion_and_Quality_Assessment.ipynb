{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RC Pakistan Cargo & Logistics - Data Ingestion and Quality Assessment\n",
    "\n",
    "This notebook covers:\n",
    "1. Data ingestion from CSV files\n",
    "2. Data quality assessment\n",
    "3. Data profiling and validation\n",
    "4. Initial data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"RC Pakistan Cargo & Logistics - Data Engineering Pipeline\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "customers_df = pd.read_csv('../data/customers.csv')\n",
    "bookings_df = pd.read_csv('../data/bookings.csv')\n",
    "shipments_df = pd.read_csv('../data/shipments.csv')\n",
    "payments_df = pd.read_csv('../data/payments.csv')\n",
    "\n",
    "print(\"Dataset Shapes:\")\n",
    "print(f\"Customers: {customers_df.shape}\")\n",
    "print(f\"Bookings: {bookings_df.shape}\")\n",
    "print(f\"Shipments: {shipments_df.shape}\")\n",
    "print(f\"Payments: {payments_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_data_quality(df, name):\n",
    "    print(f\"\\n{name} Data Quality Assessment:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nMissing Values:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"\\nNo missing values found\")\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nDuplicate rows: {duplicates}\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assess each dataset\n",
    "customers_df = assess_data_quality(customers_df, \"Customers\")\n",
    "bookings_df = assess_data_quality(bookings_df, \"Bookings\")\n",
    "shipments_df = assess_data_quality(shipments_df, \"Shipments\")\n",
    "payments_df = assess_data_quality(payments_df, \"Payments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer distribution by city\n",
    "plt.figure(figsize=(12, 6))\n",
    "customers_df['City'].value_counts().plot(kind='bar')\n",
    "plt.title('Customer Distribution by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Booking status distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "bookings_df['Status'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Booking Status Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "# Transport mode analysis\n",
    "plt.figure(figsize=(8, 6))\n",
    "bookings_df['Mode'].value_counts().plot(kind='bar')\n",
    "plt.title('Transport Mode Distribution')\n",
    "plt.xlabel('Transport Mode')\n",
    "plt.ylabel('Number of Bookings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Validation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "date_columns = {\n",
    "    'customers_df': ['CreatedDate'],\n",
    "    'bookings_df': ['BookingDate'],\n",
    "    'shipments_df': ['ShipmentDate', 'ExpectedDelivery'],\n",
    "    'payments_df': ['Date']\n",
    "}\n",
    "\n",
    "for df_name, cols in date_columns.items():\n",
    "    df = locals()[df_name]\n",
    "    for col in cols:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    print(f\"Converted date columns in {df_name}: {cols}\")\n",
    "\n",
    "# Validate business rules\n",
    "print(\"\\nBusiness Rule Validations:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Check if shipment date is after booking date\n",
    "merged_dates = bookings_df.merge(shipments_df, on='BookingID')\n",
    "invalid_dates = merged_dates[merged_dates['ShipmentDate'] < merged_dates['BookingDate']]\n",
    "print(f\"Invalid shipment dates (before booking): {len(invalid_dates)}\")\n",
    "\n",
    "# Check weight consistency\n",
    "weight_stats = bookings_df['WeightKG'].describe()\n",
    "print(f\"\\nWeight Statistics:\")\n",
    "print(weight_stats)\n",
    "\n",
    "# Check for negative amounts\n",
    "negative_amounts = payments_df[payments_df['Amount'] < 0]\n",
    "print(f\"\\nNegative payment amounts: {len(negative_amounts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create processed data directory\n",
    "os.makedirs('../processed_data', exist_ok=True)\n",
    "\n",
    "# Save cleaned datasets\n",
    "customers_df.to_csv('../processed_data/customers_clean.csv', index=False)\n",
    "bookings_df.to_csv('../processed_data/bookings_clean.csv', index=False)\n",
    "shipments_df.to_csv('../processed_data/shipments_clean.csv', index=False)\n",
    "payments_df.to_csv('../processed_data/payments_clean.csv', index=False)\n",
    "\n",
    "print(\"Cleaned data saved to processed_data/ directory\")\n",
    "print(\"Data ingestion and quality assessment completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}